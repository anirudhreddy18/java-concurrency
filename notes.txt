Process
code, data & state information
independent
there can be 100s of processes and os manages them

Thread
subset of process
a process can have multiple threads
light weight less overhead to create & terminate
os can switch b/w threads faster than processes

a java application runs in one process and can spin up multiple threads
each java app executes in its own instance of the JVM
each JVM instance is a separate independent process

by default java app takes 1 core and that is main thread

concurrency: it appears threads are running in parallel but only 1 thread can execute at a gievn time
Parallelism: it means using multi cores and multiple threads running at same time

-----------------------------------------------UDEMY-------------------------------------------------------
Concurrrency -- Responsiveness
Parallelism. --- Performance

OS
Disk/Hardrive -> All our applications reside in the hard drive just like a file(Text Editor, Web Browser)
Memory -> when user runs an application os takes the progrsm & creates an instance of application in RAM
this instance is called a process and is isolated from any other process
Process (Context) 
PID -> process ID
Files -> application opens for reading & writing
Heap -> for storing the data
code -> program instructions to be executed on CPU
Main Thread -> has a stack & instruction pointer
in a multi threaded application each thread comes with its own stack & instruction pointer all of the rest are shared
stack -> stores local variables & passed into functions
instruction pointer -> Address of next instruction to execute

Context Switch
Each process is independent
and each process has many threads
stop thread 1
schedule thread 1 out
schedule thread2
start thread2
its not cheap and is the price of multitasking (concurrency)
Each Thread consumes resoucres in the CPU & memory
switching involves stotring data for 1 thread and restorign data for another thread
too many threads causes decreases perdformance
threads consumes less resources than processes. context switching b/w 2 threads in same process in cheaper than from threads in different processes
Thread share a lot of data

Threads Scheduling 
depends on OS
we cannot control this 

Threads vs processes
prefer if tasks share a lot of data
threads are much faster to create & destroy
swithcing b/w threads in process is cheaper than switching b/w multiple processes

to prevent a thread from blocking our app from exiting we set the thread to be Daemon thread
Threads always run independently
order of execution is out of control can be sequential, concurrent, parallel

Thread.Join() waits for all threads to be done
thread1.join() waits for the thread to complete

Performance
Latency -> time taken to complete a task
Throughput -> amount of tasks completed in a given period
measured in tasks/time

increase latency:
running subtasks in parallel and running them on different cores
os will do best to schedule them to different core to make max use of hardware

no of threads = no of cores is optimal only if all threads are runnable and can run without interruption(no io/ blocking/sleep calls)
assumption of nothig else that consumes lot of CPU (for ex a dedicated server)
hyperthreading -> each physical core can run 2 threads can parallel
having more threads than cores is counter productive

Latency = T/N
Throughput 
Approach 1 breaking tasks into subtasks throughput < N/T (N -> no of threads t -> time to execute original task)
since we need to create threads start them and wait for all to complete
Approach 2 running each task in parallel o different threads throughput = N/T
here tasks are unrelated and independent to each other so therefore achieves max throughput

Thread Pooling
creating threads once and reusing them for future tasks instead of recreating them every time.
if all the threads are busy in the pool tasks will be waiting in the queue until a thread becomes available
not trivial
JDK comes only with a few implementations
fixed thread poolexecutor

For a http request time taken to get a response after a request is made is called latency
where as throughput = number of requests/time taken to get response

if no call is blocking always execute no of threads = number of cores to achieve max throughput
if there is blocking call like DB always execute no of threads > number of cores to achieve max throughput since most of thread are going to be idle waiting response from DB.

Stack
local primitive types and local references
all variables belong to thread executing on stack
statically allocated whrn thread is created
stack size is fixed and relatively small
calling hierarchy is too deep may get stack overflow exception (recursion)

Heap
all threads has access to heap memory and share them and allocate 
objects(strings , collections etc anything with new operator), members of classes, static variables
Managed by GC
Members of classes exist as long as their parent objects exist
static varibles forever entire lifecycle

References vs Objects
Object referencevar1 = new Object();
Object referencevar2 = referencevar1; // they are asigned same address

References
can be allocated on stack
can be allocated on heap if they are members of class

objects
Always allocated on heap

Resource sharing between threads

Atomic operation
